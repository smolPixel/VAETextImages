{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ab7c2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import subprocess, os\n",
    "from process_data import *\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from data.dataset import create_datasets\n",
    "from Generator.Generator import generator\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "bs = 100\n",
    "# MNIST Dataset\n",
    "train_dataset = datasets.MNIST(root='./mnist_data/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = datasets.MNIST(root='./mnist_data/', train=False, transform=transforms.ToTensor(), download=False)\n",
    "\n",
    "# Data Loader (Input Pipeline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=bs, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1efb0443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img=train_dataset[7]\n",
    "plt.imshow(img[0].view(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2761fb54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "921ecc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VAE\n",
    "\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, x_dim, h_dim1, h_dim2, z_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        # encoder part\n",
    "        self.fc1 = nn.Linear(x_dim, h_dim1)\n",
    "        self.fc2 = nn.Linear(h_dim1, h_dim2)\n",
    "        self.fc31 = nn.Linear(h_dim2, z_dim)\n",
    "        self.fc32 = nn.Linear(h_dim2, z_dim)\n",
    "        # decoder part\n",
    "        self.fc4 = nn.Linear(z_dim, h_dim2)\n",
    "        self.fc5 = nn.Linear(h_dim2, h_dim1)\n",
    "        self.fc6 = nn.Linear(h_dim1, x_dim)\n",
    "        \n",
    "    def encoder(self, x):\n",
    "        h = F.relu(self.fc1(x))\n",
    "        h = F.relu(self.fc2(h))\n",
    "        return self.fc31(h), self.fc32(h) # mu, log_var\n",
    "    \n",
    "    def sampling(self, mu, log_var):\n",
    "        std = torch.exp(0.5*log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps.mul(std).add_(mu) # return z sample\n",
    "        \n",
    "    def decoder(self, z):\n",
    "        h = F.relu(self.fc4(z))\n",
    "        h = F.relu(self.fc5(h))\n",
    "        return F.sigmoid(self.fc6(h)) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encoder(x.view(-1, 784))\n",
    "        z = self.sampling(mu, log_var)\n",
    "        return self.decoder(z), mu, log_var\n",
    "\n",
    "# build model\n",
    "vae = VAE(x_dim=784, h_dim1= 512, h_dim2=256, z_dim=2)\n",
    "if torch.cuda.is_available():\n",
    "    vae.cuda()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc1942f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(vae.parameters())\n",
    "# return reconstruction error + KL divergence losses\n",
    "def loss_function(recon_x, x, mu, log_var):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5afd570",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    vae.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        recon_batch, mu, log_var = vae(data)\n",
    "        loss = loss_function(recon_batch, data, mu, log_var)\n",
    "        \n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item() / len(data)))\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss / len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96ae7e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def test():\n",
    "    vae.eval()\n",
    "    test_loss= 0\n",
    "    with torch.no_grad():\n",
    "        for data, _ in test_loader:\n",
    "            data = data.cuda()\n",
    "            recon, mu, log_var = vae(data)\n",
    "            \n",
    "            # sum up batch loss\n",
    "            test_loss += loss_function(recon, data, mu, log_var).item()\n",
    "        \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86a1c80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/piedboef/Documents/VAETI/venv/lib/python3.10/site-packages/torch/nn/functional.py:1944: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 542.158047\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 187.161035\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 170.555820\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 164.830273\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 167.527109\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 162.605088\n",
      "====> Epoch: 1 Average loss: 177.9354\n",
      "====> Test set loss: 161.7420\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 152.200293\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 158.943535\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 160.054756\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 157.333984\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 154.768789\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 158.558145\n",
      "====> Epoch: 2 Average loss: 157.4288\n",
      "====> Test set loss: 154.4403\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 153.457998\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 156.636973\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 162.320879\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 142.909971\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 147.524424\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 159.384512\n",
      "====> Epoch: 3 Average loss: 152.2005\n",
      "====> Test set loss: 150.1862\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 150.190635\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 151.889141\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 159.668730\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 145.041094\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 151.558477\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 142.567852\n",
      "====> Epoch: 4 Average loss: 149.0786\n",
      "====> Test set loss: 148.5659\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 149.451689\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 139.848428\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 141.843496\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 147.342178\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 137.631445\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 148.960342\n",
      "====> Epoch: 5 Average loss: 146.8770\n",
      "====> Test set loss: 146.6206\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 136.245117\n",
      "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 140.262656\n",
      "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 144.667344\n",
      "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 139.419551\n",
      "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 144.727822\n",
      "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 151.747842\n",
      "====> Epoch: 6 Average loss: 145.4088\n",
      "====> Test set loss: 145.3752\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 146.603936\n",
      "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 146.178799\n",
      "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 134.456846\n",
      "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 142.962617\n",
      "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 143.117363\n",
      "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 148.452822\n",
      "====> Epoch: 7 Average loss: 144.4151\n",
      "====> Test set loss: 145.0057\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 149.377988\n",
      "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 132.142793\n",
      "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 149.373916\n",
      "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 142.752021\n",
      "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 127.473457\n",
      "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 134.922012\n",
      "====> Epoch: 8 Average loss: 143.5426\n",
      "====> Test set loss: 144.2194\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 138.841719\n",
      "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 143.785127\n",
      "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 145.920391\n",
      "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 134.520312\n",
      "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 144.345391\n",
      "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 137.457598\n",
      "====> Epoch: 9 Average loss: 142.8227\n",
      "====> Test set loss: 143.0181\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 148.554189\n",
      "Train Epoch: 10 [10000/60000 (17%)]\tLoss: 146.607666\n",
      "Train Epoch: 10 [20000/60000 (33%)]\tLoss: 140.631973\n",
      "Train Epoch: 10 [30000/60000 (50%)]\tLoss: 143.744639\n",
      "Train Epoch: 10 [40000/60000 (67%)]\tLoss: 135.858955\n",
      "Train Epoch: 10 [50000/60000 (83%)]\tLoss: 132.588447\n",
      "====> Epoch: 10 Average loss: 142.2076\n",
      "====> Test set loss: 142.9581\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 149.284521\n",
      "Train Epoch: 11 [10000/60000 (17%)]\tLoss: 140.271006\n",
      "Train Epoch: 11 [20000/60000 (33%)]\tLoss: 136.940576\n",
      "Train Epoch: 11 [30000/60000 (50%)]\tLoss: 144.596826\n",
      "Train Epoch: 11 [40000/60000 (67%)]\tLoss: 139.276650\n",
      "Train Epoch: 11 [50000/60000 (83%)]\tLoss: 132.552617\n",
      "====> Epoch: 11 Average loss: 141.6378\n",
      "====> Test set loss: 142.4690\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 138.048125\n",
      "Train Epoch: 12 [10000/60000 (17%)]\tLoss: 143.406523\n",
      "Train Epoch: 12 [20000/60000 (33%)]\tLoss: 145.304062\n",
      "Train Epoch: 12 [30000/60000 (50%)]\tLoss: 141.479883\n",
      "Train Epoch: 12 [40000/60000 (67%)]\tLoss: 144.797510\n",
      "Train Epoch: 12 [50000/60000 (83%)]\tLoss: 133.742920\n",
      "====> Epoch: 12 Average loss: 141.1446\n",
      "====> Test set loss: 142.0892\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 145.876523\n",
      "Train Epoch: 13 [10000/60000 (17%)]\tLoss: 134.164805\n",
      "Train Epoch: 13 [20000/60000 (33%)]\tLoss: 134.971807\n",
      "Train Epoch: 13 [30000/60000 (50%)]\tLoss: 143.351924\n",
      "Train Epoch: 13 [40000/60000 (67%)]\tLoss: 140.707773\n",
      "Train Epoch: 13 [50000/60000 (83%)]\tLoss: 145.008379\n",
      "====> Epoch: 13 Average loss: 140.8302\n",
      "====> Test set loss: 141.4887\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 140.186982\n",
      "Train Epoch: 14 [10000/60000 (17%)]\tLoss: 137.233486\n",
      "Train Epoch: 14 [20000/60000 (33%)]\tLoss: 140.870937\n",
      "Train Epoch: 14 [30000/60000 (50%)]\tLoss: 136.964258\n",
      "Train Epoch: 14 [40000/60000 (67%)]\tLoss: 131.239629\n",
      "Train Epoch: 14 [50000/60000 (83%)]\tLoss: 139.758809\n",
      "====> Epoch: 14 Average loss: 140.3305\n",
      "====> Test set loss: 141.2836\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 136.213135\n",
      "Train Epoch: 15 [10000/60000 (17%)]\tLoss: 137.877197\n",
      "Train Epoch: 15 [20000/60000 (33%)]\tLoss: 147.810020\n",
      "Train Epoch: 15 [30000/60000 (50%)]\tLoss: 137.228447\n",
      "Train Epoch: 15 [40000/60000 (67%)]\tLoss: 143.067324\n",
      "Train Epoch: 15 [50000/60000 (83%)]\tLoss: 146.504121\n",
      "====> Epoch: 15 Average loss: 139.9272\n",
      "====> Test set loss: 141.3796\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 139.824512\n",
      "Train Epoch: 16 [10000/60000 (17%)]\tLoss: 142.479736\n",
      "Train Epoch: 16 [20000/60000 (33%)]\tLoss: 152.921602\n",
      "Train Epoch: 16 [30000/60000 (50%)]\tLoss: 139.951787\n",
      "Train Epoch: 16 [40000/60000 (67%)]\tLoss: 141.653486\n",
      "Train Epoch: 16 [50000/60000 (83%)]\tLoss: 134.655430\n",
      "====> Epoch: 16 Average loss: 139.7204\n",
      "====> Test set loss: 141.1843\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 135.254600\n",
      "Train Epoch: 17 [10000/60000 (17%)]\tLoss: 140.881416\n",
      "Train Epoch: 17 [20000/60000 (33%)]\tLoss: 149.517900\n",
      "Train Epoch: 17 [30000/60000 (50%)]\tLoss: 140.331348\n",
      "Train Epoch: 17 [40000/60000 (67%)]\tLoss: 131.567090\n",
      "Train Epoch: 17 [50000/60000 (83%)]\tLoss: 141.087363\n",
      "====> Epoch: 17 Average loss: 139.4281\n",
      "====> Test set loss: 140.7909\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 148.090469\n",
      "Train Epoch: 18 [10000/60000 (17%)]\tLoss: 149.612246\n",
      "Train Epoch: 18 [20000/60000 (33%)]\tLoss: 139.630898\n",
      "Train Epoch: 18 [30000/60000 (50%)]\tLoss: 145.010674\n",
      "Train Epoch: 18 [40000/60000 (67%)]\tLoss: 139.348066\n",
      "Train Epoch: 18 [50000/60000 (83%)]\tLoss: 132.164932\n",
      "====> Epoch: 18 Average loss: 139.0160\n",
      "====> Test set loss: 140.5701\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 141.231602\n",
      "Train Epoch: 19 [10000/60000 (17%)]\tLoss: 147.049102\n",
      "Train Epoch: 19 [20000/60000 (33%)]\tLoss: 134.419404\n",
      "Train Epoch: 19 [30000/60000 (50%)]\tLoss: 150.661328\n",
      "Train Epoch: 19 [40000/60000 (67%)]\tLoss: 142.179990\n",
      "Train Epoch: 19 [50000/60000 (83%)]\tLoss: 132.379658\n",
      "====> Epoch: 19 Average loss: 138.7864\n",
      "====> Test set loss: 140.2800\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 129.432246\n",
      "Train Epoch: 20 [10000/60000 (17%)]\tLoss: 138.384658\n",
      "Train Epoch: 20 [20000/60000 (33%)]\tLoss: 137.137773\n",
      "Train Epoch: 20 [30000/60000 (50%)]\tLoss: 142.224199\n",
      "Train Epoch: 20 [40000/60000 (67%)]\tLoss: 130.821182\n",
      "Train Epoch: 20 [50000/60000 (83%)]\tLoss: 131.718457\n",
      "====> Epoch: 20 Average loss: 138.4741\n",
      "====> Test set loss: 141.0769\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLoss: 134.861162\n",
      "Train Epoch: 21 [10000/60000 (17%)]\tLoss: 139.427451\n",
      "Train Epoch: 21 [20000/60000 (33%)]\tLoss: 146.675752\n",
      "Train Epoch: 21 [30000/60000 (50%)]\tLoss: 138.345176\n",
      "Train Epoch: 21 [40000/60000 (67%)]\tLoss: 135.350176\n",
      "Train Epoch: 21 [50000/60000 (83%)]\tLoss: 138.058984\n",
      "====> Epoch: 21 Average loss: 138.2888\n",
      "====> Test set loss: 139.8094\n",
      "Train Epoch: 22 [0/60000 (0%)]\tLoss: 140.673184\n",
      "Train Epoch: 22 [10000/60000 (17%)]\tLoss: 136.468066\n",
      "Train Epoch: 22 [20000/60000 (33%)]\tLoss: 146.877129\n",
      "Train Epoch: 22 [30000/60000 (50%)]\tLoss: 134.215928\n",
      "Train Epoch: 22 [40000/60000 (67%)]\tLoss: 139.273203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 22 [50000/60000 (83%)]\tLoss: 136.586914\n",
      "====> Epoch: 22 Average loss: 138.0841\n",
      "====> Test set loss: 139.6608\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLoss: 133.821973\n",
      "Train Epoch: 23 [10000/60000 (17%)]\tLoss: 136.530869\n",
      "Train Epoch: 23 [20000/60000 (33%)]\tLoss: 132.201240\n",
      "Train Epoch: 23 [30000/60000 (50%)]\tLoss: 140.735059\n",
      "Train Epoch: 23 [40000/60000 (67%)]\tLoss: 151.719990\n",
      "Train Epoch: 23 [50000/60000 (83%)]\tLoss: 143.154502\n",
      "====> Epoch: 23 Average loss: 137.9407\n",
      "====> Test set loss: 139.5661\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLoss: 134.475215\n",
      "Train Epoch: 24 [10000/60000 (17%)]\tLoss: 133.180410\n",
      "Train Epoch: 24 [20000/60000 (33%)]\tLoss: 139.737139\n",
      "Train Epoch: 24 [30000/60000 (50%)]\tLoss: 147.200332\n",
      "Train Epoch: 24 [40000/60000 (67%)]\tLoss: 131.547207\n",
      "Train Epoch: 24 [50000/60000 (83%)]\tLoss: 139.145352\n",
      "====> Epoch: 24 Average loss: 137.7819\n",
      "====> Test set loss: 139.4800\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLoss: 131.848926\n",
      "Train Epoch: 25 [10000/60000 (17%)]\tLoss: 132.792510\n",
      "Train Epoch: 25 [20000/60000 (33%)]\tLoss: 132.612500\n",
      "Train Epoch: 25 [30000/60000 (50%)]\tLoss: 135.342910\n",
      "Train Epoch: 25 [40000/60000 (67%)]\tLoss: 140.779561\n",
      "Train Epoch: 25 [50000/60000 (83%)]\tLoss: 132.216270\n",
      "====> Epoch: 25 Average loss: 137.5122\n",
      "====> Test set loss: 139.2473\n",
      "Train Epoch: 26 [0/60000 (0%)]\tLoss: 142.822588\n",
      "Train Epoch: 26 [10000/60000 (17%)]\tLoss: 139.849014\n",
      "Train Epoch: 26 [20000/60000 (33%)]\tLoss: 141.262402\n",
      "Train Epoch: 26 [30000/60000 (50%)]\tLoss: 136.932666\n",
      "Train Epoch: 26 [40000/60000 (67%)]\tLoss: 142.721084\n",
      "Train Epoch: 26 [50000/60000 (83%)]\tLoss: 136.663516\n",
      "====> Epoch: 26 Average loss: 137.3869\n",
      "====> Test set loss: 139.4746\n",
      "Train Epoch: 27 [0/60000 (0%)]\tLoss: 139.658828\n",
      "Train Epoch: 27 [10000/60000 (17%)]\tLoss: 136.428574\n",
      "Train Epoch: 27 [20000/60000 (33%)]\tLoss: 150.947441\n",
      "Train Epoch: 27 [30000/60000 (50%)]\tLoss: 134.376982\n",
      "Train Epoch: 27 [40000/60000 (67%)]\tLoss: 139.709219\n",
      "Train Epoch: 27 [50000/60000 (83%)]\tLoss: 138.473271\n",
      "====> Epoch: 27 Average loss: 136.9753\n",
      "====> Test set loss: 139.3713\n",
      "Train Epoch: 28 [0/60000 (0%)]\tLoss: 135.076035\n",
      "Train Epoch: 28 [10000/60000 (17%)]\tLoss: 136.214346\n",
      "Train Epoch: 28 [20000/60000 (33%)]\tLoss: 132.815459\n",
      "Train Epoch: 28 [30000/60000 (50%)]\tLoss: 137.414385\n",
      "Train Epoch: 28 [40000/60000 (67%)]\tLoss: 137.939492\n",
      "Train Epoch: 28 [50000/60000 (83%)]\tLoss: 138.625596\n",
      "====> Epoch: 28 Average loss: 136.8145\n",
      "====> Test set loss: 139.8563\n",
      "Train Epoch: 29 [0/60000 (0%)]\tLoss: 133.360967\n",
      "Train Epoch: 29 [10000/60000 (17%)]\tLoss: 140.073750\n",
      "Train Epoch: 29 [20000/60000 (33%)]\tLoss: 132.445391\n",
      "Train Epoch: 29 [30000/60000 (50%)]\tLoss: 136.552432\n",
      "Train Epoch: 29 [40000/60000 (67%)]\tLoss: 131.118828\n",
      "Train Epoch: 29 [50000/60000 (83%)]\tLoss: 139.657578\n",
      "====> Epoch: 29 Average loss: 137.1147\n",
      "====> Test set loss: 139.2265\n",
      "Train Epoch: 30 [0/60000 (0%)]\tLoss: 139.505469\n",
      "Train Epoch: 30 [10000/60000 (17%)]\tLoss: 136.514531\n",
      "Train Epoch: 30 [20000/60000 (33%)]\tLoss: 136.554844\n",
      "Train Epoch: 30 [30000/60000 (50%)]\tLoss: 141.893418\n",
      "Train Epoch: 30 [40000/60000 (67%)]\tLoss: 136.852822\n",
      "Train Epoch: 30 [50000/60000 (83%)]\tLoss: 134.971348\n",
      "====> Epoch: 30 Average loss: 136.8150\n",
      "====> Test set loss: 138.7908\n",
      "Train Epoch: 31 [0/60000 (0%)]\tLoss: 140.610479\n",
      "Train Epoch: 31 [10000/60000 (17%)]\tLoss: 135.931865\n",
      "Train Epoch: 31 [20000/60000 (33%)]\tLoss: 131.809092\n",
      "Train Epoch: 31 [30000/60000 (50%)]\tLoss: 136.290010\n",
      "Train Epoch: 31 [40000/60000 (67%)]\tLoss: 131.726963\n",
      "Train Epoch: 31 [50000/60000 (83%)]\tLoss: 130.379873\n",
      "====> Epoch: 31 Average loss: 136.4759\n",
      "====> Test set loss: 138.6624\n",
      "Train Epoch: 32 [0/60000 (0%)]\tLoss: 135.353145\n",
      "Train Epoch: 32 [10000/60000 (17%)]\tLoss: 137.194209\n",
      "Train Epoch: 32 [20000/60000 (33%)]\tLoss: 131.051367\n",
      "Train Epoch: 32 [30000/60000 (50%)]\tLoss: 135.209902\n",
      "Train Epoch: 32 [40000/60000 (67%)]\tLoss: 140.768955\n",
      "Train Epoch: 32 [50000/60000 (83%)]\tLoss: 137.189111\n",
      "====> Epoch: 32 Average loss: 136.2219\n",
      "====> Test set loss: 138.4902\n",
      "Train Epoch: 33 [0/60000 (0%)]\tLoss: 138.900264\n",
      "Train Epoch: 33 [10000/60000 (17%)]\tLoss: 141.583984\n",
      "Train Epoch: 33 [20000/60000 (33%)]\tLoss: 136.412822\n",
      "Train Epoch: 33 [30000/60000 (50%)]\tLoss: 138.309297\n",
      "Train Epoch: 33 [40000/60000 (67%)]\tLoss: 139.532471\n",
      "Train Epoch: 33 [50000/60000 (83%)]\tLoss: 135.654629\n",
      "====> Epoch: 33 Average loss: 136.1497\n",
      "====> Test set loss: 138.6068\n",
      "Train Epoch: 34 [0/60000 (0%)]\tLoss: 141.439629\n",
      "Train Epoch: 34 [10000/60000 (17%)]\tLoss: 131.577275\n",
      "Train Epoch: 34 [20000/60000 (33%)]\tLoss: 139.522109\n",
      "Train Epoch: 34 [30000/60000 (50%)]\tLoss: 129.855059\n",
      "Train Epoch: 34 [40000/60000 (67%)]\tLoss: 133.567207\n",
      "Train Epoch: 34 [50000/60000 (83%)]\tLoss: 137.965410\n",
      "====> Epoch: 34 Average loss: 136.0783\n",
      "====> Test set loss: 138.9593\n",
      "Train Epoch: 35 [0/60000 (0%)]\tLoss: 130.996133\n",
      "Train Epoch: 35 [10000/60000 (17%)]\tLoss: 134.254746\n",
      "Train Epoch: 35 [20000/60000 (33%)]\tLoss: 138.044688\n",
      "Train Epoch: 35 [30000/60000 (50%)]\tLoss: 131.312725\n",
      "Train Epoch: 35 [40000/60000 (67%)]\tLoss: 129.757285\n",
      "Train Epoch: 35 [50000/60000 (83%)]\tLoss: 142.174824\n",
      "====> Epoch: 35 Average loss: 136.0047\n",
      "====> Test set loss: 138.3617\n",
      "Train Epoch: 36 [0/60000 (0%)]\tLoss: 134.054141\n",
      "Train Epoch: 36 [10000/60000 (17%)]\tLoss: 138.879619\n",
      "Train Epoch: 36 [20000/60000 (33%)]\tLoss: 137.502578\n",
      "Train Epoch: 36 [30000/60000 (50%)]\tLoss: 132.020859\n",
      "Train Epoch: 36 [40000/60000 (67%)]\tLoss: 139.150293\n",
      "Train Epoch: 36 [50000/60000 (83%)]\tLoss: 133.990557\n",
      "====> Epoch: 36 Average loss: 136.0083\n",
      "====> Test set loss: 138.5757\n",
      "Train Epoch: 37 [0/60000 (0%)]\tLoss: 135.507021\n",
      "Train Epoch: 37 [10000/60000 (17%)]\tLoss: 150.972793\n",
      "Train Epoch: 37 [20000/60000 (33%)]\tLoss: 141.092803\n",
      "Train Epoch: 37 [30000/60000 (50%)]\tLoss: 138.445264\n",
      "Train Epoch: 37 [40000/60000 (67%)]\tLoss: 136.169014\n",
      "Train Epoch: 37 [50000/60000 (83%)]\tLoss: 139.009111\n",
      "====> Epoch: 37 Average loss: 135.7718\n",
      "====> Test set loss: 138.2781\n",
      "Train Epoch: 38 [0/60000 (0%)]\tLoss: 132.828398\n",
      "Train Epoch: 38 [10000/60000 (17%)]\tLoss: 134.852188\n",
      "Train Epoch: 38 [20000/60000 (33%)]\tLoss: 135.463398\n",
      "Train Epoch: 38 [30000/60000 (50%)]\tLoss: 143.614639\n",
      "Train Epoch: 38 [40000/60000 (67%)]\tLoss: 135.858242\n",
      "Train Epoch: 38 [50000/60000 (83%)]\tLoss: 131.889971\n",
      "====> Epoch: 38 Average loss: 135.5175\n",
      "====> Test set loss: 138.3388\n",
      "Train Epoch: 39 [0/60000 (0%)]\tLoss: 136.235508\n",
      "Train Epoch: 39 [10000/60000 (17%)]\tLoss: 133.110352\n",
      "Train Epoch: 39 [20000/60000 (33%)]\tLoss: 127.188789\n",
      "Train Epoch: 39 [30000/60000 (50%)]\tLoss: 136.980332\n",
      "Train Epoch: 39 [40000/60000 (67%)]\tLoss: 142.909160\n",
      "Train Epoch: 39 [50000/60000 (83%)]\tLoss: 131.154521\n",
      "====> Epoch: 39 Average loss: 135.6824\n",
      "====> Test set loss: 138.5876\n",
      "Train Epoch: 40 [0/60000 (0%)]\tLoss: 143.277607\n",
      "Train Epoch: 40 [10000/60000 (17%)]\tLoss: 138.973994\n",
      "Train Epoch: 40 [20000/60000 (33%)]\tLoss: 130.167471\n",
      "Train Epoch: 40 [30000/60000 (50%)]\tLoss: 134.947637\n",
      "Train Epoch: 40 [40000/60000 (67%)]\tLoss: 140.349219\n",
      "Train Epoch: 40 [50000/60000 (83%)]\tLoss: 132.992529\n",
      "====> Epoch: 40 Average loss: 135.4508\n",
      "====> Test set loss: 138.1710\n",
      "Train Epoch: 41 [0/60000 (0%)]\tLoss: 138.797578\n",
      "Train Epoch: 41 [10000/60000 (17%)]\tLoss: 131.523750\n",
      "Train Epoch: 41 [20000/60000 (33%)]\tLoss: 137.627813\n",
      "Train Epoch: 41 [30000/60000 (50%)]\tLoss: 126.950996\n",
      "Train Epoch: 41 [40000/60000 (67%)]\tLoss: 140.945664\n",
      "Train Epoch: 41 [50000/60000 (83%)]\tLoss: 140.830459\n",
      "====> Epoch: 41 Average loss: 135.4790\n",
      "====> Test set loss: 138.3881\n",
      "Train Epoch: 42 [0/60000 (0%)]\tLoss: 139.322402\n",
      "Train Epoch: 42 [10000/60000 (17%)]\tLoss: 138.501006\n",
      "Train Epoch: 42 [20000/60000 (33%)]\tLoss: 135.086260\n",
      "Train Epoch: 42 [30000/60000 (50%)]\tLoss: 131.456562\n",
      "Train Epoch: 42 [40000/60000 (67%)]\tLoss: 138.282891\n",
      "Train Epoch: 42 [50000/60000 (83%)]\tLoss: 140.635156\n",
      "====> Epoch: 42 Average loss: 135.4268\n",
      "====> Test set loss: 138.0159\n",
      "Train Epoch: 43 [0/60000 (0%)]\tLoss: 136.039648\n",
      "Train Epoch: 43 [10000/60000 (17%)]\tLoss: 135.579844\n",
      "Train Epoch: 43 [20000/60000 (33%)]\tLoss: 144.356045\n",
      "Train Epoch: 43 [30000/60000 (50%)]\tLoss: 136.161895\n",
      "Train Epoch: 43 [40000/60000 (67%)]\tLoss: 131.301836\n",
      "Train Epoch: 43 [50000/60000 (83%)]\tLoss: 136.264492\n",
      "====> Epoch: 43 Average loss: 135.3012\n",
      "====> Test set loss: 138.7155\n",
      "Train Epoch: 44 [0/60000 (0%)]\tLoss: 136.183896\n",
      "Train Epoch: 44 [10000/60000 (17%)]\tLoss: 133.495703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 44 [20000/60000 (33%)]\tLoss: 133.695264\n",
      "Train Epoch: 44 [30000/60000 (50%)]\tLoss: 129.313770\n",
      "Train Epoch: 44 [40000/60000 (67%)]\tLoss: 133.089482\n",
      "Train Epoch: 44 [50000/60000 (83%)]\tLoss: 137.078252\n",
      "====> Epoch: 44 Average loss: 135.2893\n",
      "====> Test set loss: 138.0811\n",
      "Train Epoch: 45 [0/60000 (0%)]\tLoss: 128.901172\n",
      "Train Epoch: 45 [10000/60000 (17%)]\tLoss: 136.373105\n",
      "Train Epoch: 45 [20000/60000 (33%)]\tLoss: 129.133789\n",
      "Train Epoch: 45 [30000/60000 (50%)]\tLoss: 144.591328\n",
      "Train Epoch: 45 [40000/60000 (67%)]\tLoss: 139.430176\n",
      "Train Epoch: 45 [50000/60000 (83%)]\tLoss: 133.093926\n",
      "====> Epoch: 45 Average loss: 135.0420\n",
      "====> Test set loss: 137.8824\n",
      "Train Epoch: 46 [0/60000 (0%)]\tLoss: 137.487998\n",
      "Train Epoch: 46 [10000/60000 (17%)]\tLoss: 133.326436\n",
      "Train Epoch: 46 [20000/60000 (33%)]\tLoss: 136.032314\n",
      "Train Epoch: 46 [30000/60000 (50%)]\tLoss: 134.350898\n",
      "Train Epoch: 46 [40000/60000 (67%)]\tLoss: 133.853174\n",
      "Train Epoch: 46 [50000/60000 (83%)]\tLoss: 127.153047\n",
      "====> Epoch: 46 Average loss: 134.7532\n",
      "====> Test set loss: 138.0964\n",
      "Train Epoch: 47 [0/60000 (0%)]\tLoss: 132.026982\n",
      "Train Epoch: 47 [10000/60000 (17%)]\tLoss: 133.901563\n",
      "Train Epoch: 47 [20000/60000 (33%)]\tLoss: 131.665508\n",
      "Train Epoch: 47 [30000/60000 (50%)]\tLoss: 133.740967\n",
      "Train Epoch: 47 [40000/60000 (67%)]\tLoss: 137.962744\n",
      "Train Epoch: 47 [50000/60000 (83%)]\tLoss: 130.276504\n",
      "====> Epoch: 47 Average loss: 134.7969\n",
      "====> Test set loss: 137.7334\n",
      "Train Epoch: 48 [0/60000 (0%)]\tLoss: 126.467207\n",
      "Train Epoch: 48 [10000/60000 (17%)]\tLoss: 142.137422\n",
      "Train Epoch: 48 [20000/60000 (33%)]\tLoss: 136.960625\n",
      "Train Epoch: 48 [30000/60000 (50%)]\tLoss: 136.439307\n",
      "Train Epoch: 48 [40000/60000 (67%)]\tLoss: 138.168877\n",
      "Train Epoch: 48 [50000/60000 (83%)]\tLoss: 126.481553\n",
      "====> Epoch: 48 Average loss: 134.8442\n",
      "====> Test set loss: 138.0893\n",
      "Train Epoch: 49 [0/60000 (0%)]\tLoss: 136.193164\n",
      "Train Epoch: 49 [10000/60000 (17%)]\tLoss: 126.255059\n",
      "Train Epoch: 49 [20000/60000 (33%)]\tLoss: 128.822295\n",
      "Train Epoch: 49 [30000/60000 (50%)]\tLoss: 136.463613\n",
      "Train Epoch: 49 [40000/60000 (67%)]\tLoss: 132.063799\n",
      "Train Epoch: 49 [50000/60000 (83%)]\tLoss: 136.938926\n",
      "====> Epoch: 49 Average loss: 134.9639\n",
      "====> Test set loss: 137.9098\n",
      "Train Epoch: 50 [0/60000 (0%)]\tLoss: 139.403037\n",
      "Train Epoch: 50 [10000/60000 (17%)]\tLoss: 129.691211\n",
      "Train Epoch: 50 [20000/60000 (33%)]\tLoss: 131.387217\n",
      "Train Epoch: 50 [30000/60000 (50%)]\tLoss: 137.711396\n",
      "Train Epoch: 50 [40000/60000 (67%)]\tLoss: 133.389639\n",
      "Train Epoch: 50 [50000/60000 (83%)]\tLoss: 128.801143\n",
      "====> Epoch: 50 Average loss: 134.6203\n",
      "====> Test set loss: 137.6985\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for epoch in range(1, 51):\n",
    "    train(epoch)\n",
    "    test()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12632064",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
